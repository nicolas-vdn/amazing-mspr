# ğŸš€ Data Processing Pipeline avec Snowflake & GitHub Actions

## ğŸ“Œ Description
Ce projet met en place une pipeline de traitement de donnÃ©es automatisÃ©e avec deux notebooks principaux.  
Chaque notebook est transformÃ© en script Python et exÃ©cutÃ© dans un conteneur Docker via des **GitHub Actions** planifiÃ©es.

---

## ğŸ“‚ Architecture du Projet

### 1. **Notebook 1 â€“ Ingestion & Transformation**
- RÃ©cupÃ¨re les donnÃ©es **RAW_DATA** depuis **Snowflake**  
- Effectue les transformations nÃ©cessaires  
- Stocke les donnÃ©es transformÃ©es dans la table **TRANSFORMED_DATA** sur **Snowflake**

### 2. **Notebook 2 â€“ Clustering & Traitement**
- RÃ©cupÃ¨re les donnÃ©es depuis la table **TRANSFORMED_DATA**  
- Applique le modÃ¨le de clustering (IA/ML adaptÃ©)  
- Stocke les rÃ©sultats traitÃ©s dans la table **PROCESSED_DATA** sur **Snowflake**

---

## âš™ï¸ ExÃ©cution AutomatisÃ©e

Chaque notebook dispose dâ€™un **workflow GitHub Actions** associÃ© :

- **DÃ©clencheurs** :  
  - Tous les jours Ã  **07h00 (UTC)** 
  - **ExÃ©cution manuelle** possible via lâ€™interface GitHub Actions  

- **Ã‰tapes automatisÃ©es** :  
  1. **Build** dâ€™une image **Docker** spÃ©cifique au notebook  
  2. CrÃ©ation dâ€™un **container**  
  3. Conversion du notebook en **script Python exÃ©cutable**  
  4. Lancement du script dans le container  

---

## ğŸ› ï¸ Stack Technique

- **Snowflake** : stockage et traitement de donnÃ©es  
- **Jupyter / Python** : langage principal pour les notebooks et scripts  
- **Docker** : conteneurisation des notebooks  
- **GitHub Actions** : orchestration CI/CD et scheduling
- **Matplotlib / Seaborn / Plotly** : analyse de donnÃ©es
- **Pandas / Scikit-learn / Kneed / Numpy / Matplotlib / Joblib** : transformations & clustering  

---

## ğŸ“¦ Organisation des DonnÃ©es

- **RAW_DATA** : donnÃ©es sources non transformÃ©es  
- **TRANSFORMED_DATA** : donnÃ©es nettoyÃ©es et prÃ©parÃ©es  
- **PROCESSED_DATA** : donnÃ©es enrichies par le clustering et prÃªtes Ã  lâ€™usage  

---

## â–¶ï¸ Utilisation Manuelle

1. Aller dans **GitHub Actions**  
2. SÃ©lectionner le workflow du **Notebook 1** (Transformation) ou **Notebook 2** (Clustering)  
3. Cliquer sur **Run workflow**  

---

## ğŸ”’ SÃ©curitÃ© & Secrets

Les credentials Snowflake et autres variables sensibles sont stockÃ©s en tant que **GitHub Secrets**, injectÃ©s dans lâ€™environnement au runtime.  
