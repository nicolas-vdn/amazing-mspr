{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark import Session\n",
    "\n",
    "# D√©finir ta configuration\n",
    "connection_parameters = {\n",
    "    \"account\": \"RSYIXFD-HT53341\",   # ex: \"xy12345.eu-central-1\"\n",
    "    \"user\": \"username\",\n",
    "    \"password\": \"password\",\n",
    "    \"warehouse\": \"COMPUTE_WH\",\n",
    "    \"database\": \"RAW_DATA\",\n",
    "    \"schema\": \"AMAZING_DATA\"\n",
    "}\n",
    "\n",
    "# Cr√©er la session\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "table = session.table(\"PROCESSED_DATA.AMAZING_DATA.CLIENT_EVENTS_CLEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b6c8f-068c-4945-9e8d-154998c75897",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49c818-4b76-4bba-baa7-74282cbe6d98",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# R√©cup√©rer un √©chantillon repr√©sentatif (ici le premier million de lignes)\n",
    "sample_df = session.table(\"PROCESSED_DATA.AMAZING_DATA.CLIENT_EVENTS_CLEAN\").limit(100000).to_pandas()\n",
    "\n",
    "sample_df[\"TOTAL_SPENT\"] = np.log1p(sample_df[\"TOTAL_SPENT\"])\n",
    "sample_df[\"TOTAL_VIEWS\"] = np.log1p(sample_df[\"TOTAL_VIEWS\"])\n",
    "sample_df[\"TOTAL_CART\"] = np.log1p(sample_df[\"TOTAL_CART\"])\n",
    "sample_df[\"TOTAL_PURCHASE\"] = np.log1p(sample_df[\"TOTAL_PURCHASE\"])\n",
    "\n",
    "scaler = RobustScaler()\n",
    "sample_scaled = scaler.fit_transform(sample_df)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(sample_scaled)\n",
    "\n",
    "sample_scaled = scaler.transform(sample_df)\n",
    "sample_pca = pca.transform(sample_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc564935-8e2d-4c27-9125-3c208b0fa60b",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b5908-eb9a-4bde-a793-0179bc99e8f3",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import Birch\n",
    "\n",
    "# --- Param√®tres ---\n",
    "batch_size = 200_000   # taille des batchs\n",
    "max_rows = 5_000_000   # limite de donn√©es pour le test\n",
    "\n",
    "# --- D√©finir le mod√®le BIRCH ---\n",
    "birch = Birch(\n",
    "    n_clusters=None,   # laisse BIRCH construire les micro-clusters\n",
    "    threshold=0.88,     # rayon max des sous-clusters (√† tuner !)\n",
    "    branching_factor=50\n",
    ")\n",
    "\n",
    "offset = 0\n",
    "processed_rows = 0\n",
    "\n",
    "while True:\n",
    "    chunk = session.table(\"PROCESSED_DATA.AMAZING_DATA.CLIENT_EVENTS_CLEAN\") \\\n",
    "                  .limit(batch_size, offset=offset).to_pandas()\n",
    "    if chunk.empty:\n",
    "        break\n",
    "\n",
    "    chunk[\"TOTAL_SPENT\"] = np.log1p(chunk[\"TOTAL_SPENT\"])\n",
    "    chunk[\"TOTAL_VIEWS\"] = np.log1p(chunk[\"TOTAL_VIEWS\"])\n",
    "    chunk[\"TOTAL_CART\"] = np.log1p(chunk[\"TOTAL_CART\"])\n",
    "    chunk[\"TOTAL_PURCHASE\"] = np.log1p(chunk[\"TOTAL_PURCHASE\"])\n",
    "    \n",
    "    # scaling avec scaler d√©j√† appris\n",
    "    chunk_scaled = scaler.transform(chunk)\n",
    "    \n",
    "    # projection PCA\n",
    "    chunk_pca = pca.transform(chunk_scaled)\n",
    "    \n",
    "    # mise √† jour du clustering BIRCH\n",
    "    birch.partial_fit(chunk_pca)\n",
    "    \n",
    "    processed_rows += len(chunk)\n",
    "    print(f\"Batch {offset // batch_size + 1} trait√© ({processed_rows} lignes)\")\n",
    "    offset += batch_size\n",
    "\n",
    "print(\"Entra√Ænement termin√© sur\", processed_rows, \"lignes\")\n",
    "\n",
    "# --- R√©sultats ---\n",
    "labels = birch.labels_\n",
    "print(\"Nombre de clusters trouv√©s :\", len(set(labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040e547-fcb7-4253-9c34-7a55b6c34e6d",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=5, random_state=42, n_init=\"auto\")\n",
    "km.fit(birch.subcluster_centers_)\n",
    "print(\"Nombre de micro-clusters cr√©√©s :\", len(birch.subcluster_centers_))\n",
    "\n",
    "# Labels finaux pour l‚Äô√©chantillon\n",
    "labels_sample = km.predict(sample_pca)\n",
    "print(\"Clusters finaux pr√©sents:\", np.unique(labels_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9a987-ca69-481d-a53b-576e08354f00",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "labels_final = km.predict(sample_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63987e4e-1191-482e-a047-bd1f7cf424a4",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# --- √âtape 3 : calcul des scores sur les clusters finaux ---\n",
    "sil_score = silhouette_score(sample_pca[:100000], labels_final[:100000])\n",
    "ch_score = calinski_harabasz_score(sample_pca[:100000], labels_final[:100000])\n",
    "db_score = davies_bouldin_score(sample_pca[:100000], labels_final[:100000])\n",
    "\n",
    "print(f\"Silhouette Score    : {sil_score:.3f}\")\n",
    "print(f\"Calinski-Harabasz   : {ch_score:.3f}\")\n",
    "print(f\"Davies-Bouldin      : {db_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4911ec-025c-49b9-820f-cedbf2b16501",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assure-toi que labels_final existe et a la m√™me longueur que sample_df\n",
    "print(\"Taille sample_df :\", len(sample_df))\n",
    "print(\"Taille labels_final :\", len(labels_final))\n",
    "\n",
    "# Ajouter les labels au DataFrame original\n",
    "df_with_clusters = sample_df.copy()\n",
    "df_with_clusters = df_with_clusters.reset_index(drop=True)  # reset index pour aligner\n",
    "df_with_clusters[\"cluster\"] = labels_final\n",
    "\n",
    "# S√©lectionner uniquement les colonnes num√©riques\n",
    "numeric_cols = df_with_clusters.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# V√©rifie que \"cluster\" est bien dans les colonnes\n",
    "if \"cluster\" not in numeric_cols:\n",
    "    numeric_cols.remove(\"cluster\")  # on ne veut pas inclure la colonne cluster dans les moyennes\n",
    "\n",
    "# Moyennes par cluster sur les colonnes num√©riques\n",
    "cluster_means = df_with_clusters.groupby(\"cluster\")[numeric_cols].mean()\n",
    "\n",
    "# Moyenne globale sur les m√™mes colonnes\n",
    "global_mean = df_with_clusters[numeric_cols].mean()\n",
    "\n",
    "# Importance relative = diff√©rence par rapport √† la moyenne globale\n",
    "feature_importance = cluster_means - global_mean\n",
    "\n",
    "# Afficher les top features par cluster\n",
    "for c in cluster_means.index:\n",
    "    cluster_size = len(df_with_clusters[df_with_clusters.cluster == c])\n",
    "    print(f\"\\nüîπ Cluster {c} ({cluster_size} points)\")\n",
    "    top_features = feature_importance.loc[c].abs().sort_values(ascending=False).head(10)\n",
    "    print(top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da752f9-b639-4b56-a975-3a076d314cd2",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "# df = table.limit(500000).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d90e81-4aa9-48bf-a0a8-000805ed9384",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# df_scaled = StandardScaler().fit_transform(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa403cc5-902e-4bfc-bda5-07583dc2d79d",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=3)\n",
    "# df_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "# print(f\"Variance expliqu√©e cumul√©e : {pca.explained_variance_ratio_.cumsum()}\")\n",
    "\n",
    "# df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ba682-c90a-4bee-b3fd-01592be061ff",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# min_samples = df_pca.shape[1] + 1\n",
    "\n",
    "# neighbors = NearestNeighbors(n_neighbors=min_samples)\n",
    "# neighbors_fit = neighbors.fit(df_pca)\n",
    "# distances, indices = neighbors_fit.kneighbors(df_pca)\n",
    "\n",
    "# # On prend la distance au dernier voisin (le k-i√®me)\n",
    "# distances = np.sort(distances[:, -1])\n",
    "\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# plt.plot(distances)\n",
    "# plt.xlabel(\"Points tri√©s\")\n",
    "# plt.ylabel(f\"Distance au {min_samples}√®me voisin\")\n",
    "# plt.title(\"k-distance plot\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bfd33-7fbc-47f6-be0a-3e81e0e74c6b",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# print(f\"Min distance: {distances.min()}\")\n",
    "# print(f\"Max distance: {distances.max()}\")\n",
    "# print(f\"Moyenne distance: {distances.mean()}\")\n",
    "# print(f\"25% quantile: {np.percentile(distances, 25)}\")\n",
    "# print(f\"50% quantile: {np.percentile(distances, 50)}\")\n",
    "# print(f\"75% quantile: {np.percentile(distances, 75)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea97ce95-8172-45c7-9563-40a21c2d0981",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "# from kneed import KneeLocator\n",
    "\n",
    "# sensitivities = [0.5, 1]\n",
    "# eps_values = []\n",
    "\n",
    "# for S in sensitivities:\n",
    "#     kneedle = KneeLocator(range(len(distances)), distances, S=S, curve='convex', direction='increasing')\n",
    "#     knee_idx = kneedle.knee\n",
    "#     if knee_idx is not None:\n",
    "#         eps = distances[knee_idx]\n",
    "#         print(f\"eps d√©tect√© avec S={S} : {eps:.4f}\")\n",
    "#         eps_values.append(eps)\n",
    "#     else:\n",
    "#         print(f\"Aucun coude d√©tect√© avec S={S}\")\n",
    "#         eps_values.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac717e63-1df3-47a7-81c9-69217317f387",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "# from sklearn.cluster import DBSCAN\n",
    "\n",
    "# max_sample_size = 1000\n",
    "\n",
    "# best_score = -1\n",
    "# best_eps = None\n",
    "# rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# for eps in eps_values:\n",
    "#     clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(df_pca)\n",
    "#     labels = clustering.labels_\n",
    "\n",
    "#     n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "#     noise_ratio = list(labels).count(-1) / len(labels)\n",
    "#     print(f\"eps={eps:.2f} -> clusters: {n_clusters}, bruit: {noise_ratio*100:.3f}%\")\n",
    "\n",
    "#     mask = labels != -1\n",
    "#     X_no_noise = df_pca[mask]\n",
    "#     labels_no_noise = labels[mask]\n",
    "\n",
    "#     # V√©rifier qu'il reste au moins 2 clusters distincts apr√®s retrait du bruit\n",
    "#     if len(set(labels_no_noise)) > 1:\n",
    "#         sample_size = min(max_sample_size, len(X_no_noise))\n",
    "#         indices = rng.choice(len(X_no_noise), sample_size, replace=False)\n",
    "#         X_sample = X_no_noise[indices]\n",
    "#         labels_sample = labels_no_noise[indices]\n",
    "\n",
    "#         sil_score = silhouette_score(X_sample, labels_sample)\n",
    "#         ch_score = calinski_harabasz_score(X_sample, labels_sample)\n",
    "#         db_score = davies_bouldin_score(X_sample, labels_sample)\n",
    "\n",
    "#         print(f\"  Silhouette Score    : {sil_score:.3f}\")\n",
    "#         print(f\"  Calinski-Harabasz   : {ch_score:.3f}\")\n",
    "#         print(f\"  Davies-Bouldin      : {db_score:.3f}\")\n",
    "\n",
    "#         if sil_score > best_score:\n",
    "#             best_score = sil_score\n",
    "#             best_eps = eps\n",
    "#     else:\n",
    "#         print(\"Pas assez de clusters valides pour calculer les scores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb3fb1-a9a3-4658-a5ed-145bbdcc077a",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "# dbscan = DBSCAN(eps=best_eps, min_samples=min_samples)\n",
    "# clusters = dbscan.fit_predict(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a520e-187e-48e9-bfed-67fb20f21b91",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# df_plot = pd.DataFrame({\n",
    "#     'PC1': df_pca[:, 0],\n",
    "#     'PC2': df_pca[:, 1],\n",
    "#     'PC3': df_pca[:, 2],\n",
    "#     'cluster': clusters\n",
    "# })\n",
    "\n",
    "# df_plot['color'] = df_plot['cluster'].apply(lambda x: 'grey' if x == -1 else f'cluster {x}')\n",
    "\n",
    "# fig = px.scatter_3d(df_plot, x='PC1', y='PC2', z='PC3',\n",
    "#                     color='color',\n",
    "#                     title='Clusters DBSCAN',\n",
    "#                     opacity=0.7,\n",
    "#                     size_max=5,\n",
    "#                     labels={'color': 'Cluster'})\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da992464-6227-422b-b07d-bcdb743f1ad7",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Supposons que df_final soit ton DataFrame des features\n",
    "# # et que labels soit la sortie de DBSCAN\n",
    "# # labels = clustering.labels_\n",
    "\n",
    "# # Ajouter les labels au DataFrame\n",
    "# df_clusters = df.copy()\n",
    "# df_clusters['cluster'] = labels\n",
    "\n",
    "# # On exclut le bruit (-1)\n",
    "# df_clusters = df_clusters[df_clusters['cluster'] != -1]\n",
    "\n",
    "# # S√©lectionner uniquement les colonnes num√©riques\n",
    "# numeric_cols = df_clusters.select_dtypes(include=[np.number]).columns\n",
    "# numeric_cols = numeric_cols.drop('cluster')  # on exclut la colonne cluster\n",
    "\n",
    "# # Moyenne par cluster\n",
    "# cluster_means = df_clusters.groupby('cluster')[numeric_cols].mean()\n",
    "\n",
    "# # Moyenne globale\n",
    "# global_mean = df[numeric_cols].mean()\n",
    "\n",
    "# # Importance relative : √©cart √† la moyenne globale\n",
    "# feature_importance = cluster_means - global_mean\n",
    "\n",
    "# # Pour chaque cluster, trier les features par importance absolue\n",
    "# for c in feature_importance.index:\n",
    "#     print(f\"\\nCluster {c}\")\n",
    "#     print(feature_importance.loc[c].abs().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa572a91-b4d3-47ea-adc6-05096b9f025f",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "CREATE STAGE IF NOT EXISTS clustering_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1371d-e9fa-4c33-ac4c-03c550e0d5a1",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# # Sauvegarde du mod√®le\n",
    "# joblib.dump(km, \"birch_kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157ed07-287c-49d7-853a-e152968046ce",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "# session.file.put(\"birch_kmeans\", \"@clustering_model\", auto_compress=False, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "tristanrib_@outlook.fr",
   "authorId": "2113048723087",
   "authorName": "TRISTANRIB",
   "lastEditTime": 1756053320670,
   "notebookId": "oazq57kizz42dbjja67r",
   "sessionId": "878cdd9e-7eca-45a8-b145-5a2db7a58f45"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
